{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pdi8lH-kXQni"
      },
      "outputs": [],
      "source": [
        "# What is a parameter?\n",
        "# In machine learning, a parameter is a variable that the model learns from training data.\n",
        "# Think of it as the internal settings of a model that get adjusted to improve predictions.\n",
        "# Parameters are the key elements that define how a model transforms input data into output."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oVmS4Fcpd70b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6q3p0gi1d7yY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F8cSaQL4d7wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What is correlation?\n",
        "# What does negative correlation mean?\n",
        "\n",
        "\n",
        "# Correlation measures the relationship between two variables—how changes in one variable correspond to changes in another. It’s commonly expressed with a value between -1 and 1:\n",
        "#Positive correlation (closer to 1): As one variable increases, the other increases too. Example: Higher temperatures tend to lead to higher ice cream sales.\n",
        "#Negative correlation (closer to -1): As one variable increases, the other decreases. Example: More time spent exercising typically leads to lower body weight.\n",
        "#Zero correlation (around 0): No consistent relationship between the variables.\n",
        "#In machine learning, correlation helps in feature selection—identifying which variables contribute meaningfully to predictions. For instance, if two features are highly correlated, one might be redundant."
      ],
      "metadata": {
        "id": "HD-b5zVLXrdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oDKz8Jofd8zL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S663I_hAd8w3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Machine Learning. What are the main components in Machine Learning?\n",
        "\n",
        "#Machine Learning (ML) is a subset of artificial intelligence (AI) that enables systems to learn from data and improve their performance without explicit programming.\n",
        "#Main Components of Machine Learning\n",
        "#data\n",
        "#Feature model\n",
        "#training process\n",
        "#evalution metrics\n",
        "#hyparameters"
      ],
      "metadata": {
        "id": "4Lhmz8PFYGFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KCY1i8d8d9O8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DI4e6DQcd9Mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How does loss value help in determining whether the model is good or not?\n",
        "\n",
        "#Loss value is a key indicator of how well a machine learning model is performing. It measures the difference between the model's predictions and the actual values in the dataset. Lower loss means better predictions, while higher loss suggests the model isn't learning effectively.\n",
        "#Model Accuracy Indicator – A low loss value usually means the model makes accurate predictions. However, loss alone isn't enough—other metrics like accuracy, precision, and recall matter too.\n",
        "#Optimization Guide – During training, algorithms like gradient descent minimize the loss by adjusting model parameters. A steadily decreasing loss indicates learning progress.\n",
        "#Overfitting vs. Underfitting – If training loss is low but test loss is high, the model is overfitting (memorizing instead of generalizing).\n",
        "#If loss is high on both training and test sets, the model is underfitting (not learning enough patterns).\n",
        "#Choosing the Right Model – Different problems require different loss functions:\n",
        "#Regression Models → Use loss functions like Mean Squared Error (MSE) or Mean Absolute Error (MAE).\n",
        "#Classification Models → Use loss functions like Cross-Entropy Loss."
      ],
      "metadata": {
        "id": "XZOcCxOjYiAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w7hes4Ved9tI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7fVgTscYd9rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kzvDZZOmd9pK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What are continuous and categorical variables?\n",
        "\n",
        "#In data analysis and machine learning, variables are classified into continuous and categorical types based on the nature of their values.\n",
        "\n",
        "1. Continuous Variables\n",
        "These take numerical values and can be measured on a scale.\n",
        "\n",
        "They can have an infinite range within a given interval.\n",
        "\n",
        "Examples:\n",
        "\n",
        "Temperature (25.3°C, 30.7°C)\n",
        "\n",
        "Income ($52,345, $78,910)\n",
        "\n",
        "Age (23.5 years, 45.8 years)\n",
        "\n",
        "Used in regression models and often require techniques like normalization or standardization before training.\n",
        "\n",
        "2. Categorical Variables\n",
        "These represent distinct categories or labels and usually don’t have a numerical meaning.\n",
        "\n",
        "Examples:\n",
        "\n",
        "Gender (Male, Female, Non-binary)\n",
        "\n",
        "Customer Feedback (Satisfied, Neutral, Dissatisfied)\n",
        "\n",
        "Car Brand (Toyota, Ford, BMW)\n",
        "\n",
        "Can be nominal (without order, e.g., car brands) or ordinal (with order, e.g., feedback levels).\n",
        "\n",
        "Often encoded using techniques like one-hot encoding or label encoding for ML models."
      ],
      "metadata": {
        "id": "ukFddERsY985"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xQ3m1ceed-5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-ouQEarDd-3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "\n",
        "#Handling categorical variables in machine learning is crucial because models require numerical input to perform calculations. Here are the common techniques used to preprocess categorical data:\n",
        "Label encoding\n",
        "onehot encoding\n",
        "ordinal encoding\n",
        "target encoding\n",
        "frequency encoding"
      ],
      "metadata": {
        "id": "sAPt7Ku8ZS1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WZQJX-Yhd_Yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tpQf7EWad_Wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8eMt0w4Ed_VK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-o2IqS5Ud_TC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nAYrxU0gd_8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ibhJCifNd_6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What is sklearn.preprocessing?\n",
        "\n",
        "# sklearn.preprocessing is a module in scikit-learn (a popular Python machine learning library) that provides a variety of tools and functions to preprocess and transform data before feeding it into machine learning models.\n",
        "# It helps prepare your data by scaling, normalizing, encoding, or transforming features.\n",
        "# Proper preprocessing can improve model performance and convergence."
      ],
      "metadata": {
        "id": "p_Cx5LSzZxJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AOdt182NeA5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t7YHK6laeA2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What is a Test set?\n",
        "\n",
        "A Test set in machine learning is a portion of the dataset reserved exclusively for evaluating the performance of a trained model.\n",
        "\n",
        "Key points about a Test set:\n",
        "It contains data the model has never seen during training.\n",
        "\n",
        "Used after training to assess how well the model generalizes to new, unseen data.\n",
        "\n",
        "Helps to estimate the model's real-world performance.\n",
        "\n",
        "Important to prevent overfitting — when a model performs well on training data but poorly on new data.\n",
        "\n"
      ],
      "metadata": {
        "id": "V6wdl7cTaO0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z6S-hhlbeAc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "58O43_SHeAa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  How do we split data for model fitting (training and testing) in Python?\n",
        "#  How do you approach a Machine Learning problem?\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# X = features, y = target labels\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,       # 20% data for testing\n",
        "    random_state=42      # for reproducibility\n",
        ")\n",
        "\n",
        "\n",
        "# How do you approach a Machine Learning problem?\n",
        "Understand the problem\n",
        "collect and explore the data\n",
        "Preprocess and split the data\n",
        "choose a model\n",
        "train the model\n",
        "evaluate the model\n",
        "final evalution and deployment\n"
      ],
      "metadata": {
        "id": "hCgI1EzXacxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YTntebZMeB2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "elTA_6oSeBzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Why do we have to perform EDA before fitting a model to the data?\n",
        "\n",
        "# To\n",
        "Understand the data\n",
        "Detect data quality issues\n",
        "Discover patterns and relationships\n",
        "Choose the right features\n",
        "Select appropriate models and methods\n",
        "Prevent garbage-in-garbage-out\n",
        "Inform preprocessing steps"
      ],
      "metadata": {
        "id": "7bSOuhH3bGEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F1-RjwFFeCc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eWKlJJT0eCa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vkFrvliBeCYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What is correlation?\n",
        "\n",
        "Correlation is a statistical measure that describes the strength and direction of a linear relationship between two variables.\n",
        "Helps understand how features relate to each other or to the target variable.\n",
        "Guides feature selection and engineering.\n",
        "Detects multicollinearity (when features are highly correlated), which can impact some models."
      ],
      "metadata": {
        "id": "Sbc3r24Ubeuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rpUSqdVpeC6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "il2AKbCVeC4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yDwzy-hSeC25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LyDP44BPeC0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l7YEBMWKeDMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WirgnkYXeDI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How can you find correlation between variables in Python?\n",
        "\n",
        "correlation = df['age'].corr(df['income'])\n",
        "print(\"Correlation between age and income:\", correlation)\n",
        "\n"
      ],
      "metadata": {
        "id": "RImCpFONbwE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f1di5NYCeEI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "njLltw6OeEGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O98tkPaFeEEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "\n",
        "# An optimizer is an algorithm or method used to adjust the parameters (weights and biases) of a machine learning model to minimize the loss (or error) function during training.\n",
        "\n",
        "The goal is to find the best parameters that reduce the difference between the predicted output and the actual target.\n",
        "\n",
        "Optimizers update the model's parameters iteratively using gradients (derivatives of the loss function)."
      ],
      "metadata": {
        "id": "aZMMFGNdcBQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ORmAerN_eE6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QCzZ7eUveE4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OBgZ4B5_eE11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What is sklearn.linear_model ?\n",
        "\n",
        "# sklearn.linear_model is a module in scikit-learn, a popular Python machine learning library, that provides linear models for regression and classification tasks.\n",
        "It provides efficient, easy-to-use implementations of fundamental linear models.\n",
        "Suitable for both regression (predicting continuous values) and classification problems.\n",
        "Supports regularization to improve generalization.\n",
        "Integrates seamlessly with other scikit-learn tools for preprocessing, model evaluation, and pipelines.\n"
      ],
      "metadata": {
        "id": "Ro5zBwQ6cKfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ha2gs451eFY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DxVqFDXaeFWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U6K8XHSheFUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What are continuous and categorical variables?\n",
        "\n",
        "#Continuous Variables\n",
        "Definition: Variables that can take any numeric value within a range (including decimals).\n",
        "Characteristics: They are measurable and often represent quantities.\n",
        "Examples:\n",
        "   Height (e.g., 170.5 cm)\n",
        "   Temperature (e.g., 23.7°C)\n",
        "\n",
        "# Categorical Variables\n",
        "Definition: Variables that represent categories or groups and take on a limited, fixed number of possible values.\n",
        "Characteristics: They describe qualities or labels, not quantities.\n",
        "Types:\n",
        "Nominal: No intrinsic order (e.g., color: red, blue, green)\n",
        "Ordinal: Have a meaningful order (e.g., rating: low, medium, high)\n",
        "Examples:\n",
        "     Gender (male, female)\n",
        "     Country (USA, India, Canada)"
      ],
      "metadata": {
        "id": "YjX5ZU5bcZfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HjVOTwRgeGKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wHGfK2djeGH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GH-jlk_1eGFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What is feature scaling? How does it help in Machine Learning?\n",
        "\n",
        "# Feature scaling is a preprocessing technique in machine learning used to normalize or standardize the range of independent variables (features).\n",
        "Since different features can have different units or scales (e.g., age in years vs. income in dollars), scaling brings them to a common scale without distorting differences in the ranges of values.\n",
        "\n",
        "Improve model performance\n",
        "Speed up convergence\n",
        "prevent bias"
      ],
      "metadata": {
        "id": "9zlEroE3cxCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HekZgmwSeG9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zjz-qEydeG6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hXGiikL3eG4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Fwec234eG2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What is sklearn.preprocessing?\n",
        "\n",
        "\n",
        "# **sklearn.preprocessing** is a module in Scikit-learn that provides utility functions and classes to transform (preprocess) your input data before feeding it into a machine learning model.\n",
        "These transformations help improve the performance, convergence, and accuracy of models.\n",
        "\n",
        "Ensures features are on similar scales\n",
        "Converts categorical data to numeric\n",
        "Handles missing values\n",
        "Improves training speed and accuracy\n",
        "Makes data suitable for model input\n",
        "\n"
      ],
      "metadata": {
        "id": "ZRB0aL3wdRw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dzeQiL-9eHU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QO76ygXpeHSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Evx_wFReHQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explain data encoding?\n",
        "\n",
        "# Data encoding is the process of converting categorical (non-numeric) data into numerical format so that machine learning algorithms can process it.\n",
        "Algorithms need numerical input\n",
        "Helps models interpret and compare categorical values\n",
        "Enables mathematical operations like distance and gradient calculations\n",
        "\n"
      ],
      "metadata": {
        "id": "CiyTsVEYdq8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v_6ZdLLWdq0c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}