{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1lKc9kr5s-3"
      },
      "outputs": [],
      "source": [
        "# 1. What is hypothesis testing in statistics?\n",
        "\n",
        "Hypothesis testing is a statistical method used to make decisions or inferences about a population based on sample data.\n",
        "It involves two competing hypotheses:\n",
        "\n",
        "1. Null Hypothesis (H0): Assumes no effect or no difference. It is the statement to be tested.\n",
        "2. Alternative Hypothesis (H1 or Ha): Represents the claim or effect we want to provide evidence for.\n",
        "\n",
        "The testing process includes:\n",
        "- Collecting sample data.\n",
        "- Calculating a test statistic.\n",
        "- Comparing the test statistic to a critical value or using a p-value.\n",
        "- Making a decision to either reject or fail to reject the null hypothesis.\n",
        "\n",
        "Hypothesis testing helps determine whether observed data provides enough evidence to support a specific claim about the population.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mTHw6Wtf6SaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W-ATal476SQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. What is the null hypothesis, and how does it differ from the alternative hypothesis?\n",
        "\n",
        "Null Hypothesis (H0):\n",
        "- It is a statement of no effect, no difference, or no change.\n",
        "- It represents the default or status quo assumption.\n",
        "- The goal of hypothesis testing is to assess whether there is enough evidence to reject the null hypothesis.\n",
        "\n",
        "Alternative Hypothesis (H1 or Ha):\n",
        "- It is a statement that contradicts the null hypothesis.\n",
        "- Represents the claim or effect we want to test or prove.\n",
        "- It suggests that there is an effect, difference, or change.\n",
        "\n",
        "Difference:\n",
        "- The null hypothesis assumes no relationship or effect, while the alternative hypothesis suggests that a relationship or effect exists.\n",
        "- Hypothesis testing evaluates whether data provides enough evidence to reject H0 in favor of H1."
      ],
      "metadata": {
        "id": "xKDWCnQ66SMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vMK4ehul6eg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zlDHFU4S6ed_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. What is the significance level in hypothesis testing, and why is it important?\n",
        "\n",
        "Significance Level (α) in Hypothesis Testing:\n",
        "\n",
        "- The significance level, denoted by alpha (α), is the threshold probability used to decide whether to reject the null hypothesis.\n",
        "- It represents the maximum risk of making a Type I error — rejecting the null hypothesis when it is actually true.\n",
        "- Common significance levels are 0.05, 0.01, and 0.10, meaning a 5%, 1%, or 10% risk of false rejection.\n",
        "- If the p-value of the test is less than or equal to α, we reject the null hypothesis; otherwise, we fail to reject it.\n",
        "- The significance level helps control the balance between sensitivity to detect an effect and the risk of false positives.\n",
        "\n",
        "Importance:\n",
        "- It sets a clear criterion for making statistical decisions.\n",
        "- Helps maintain the reliability and validity of conclusions drawn from data."
      ],
      "metadata": {
        "id": "rDao4VDU6ebS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FM-7kcsY6wYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BfqRHavK6wWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.  What does a P-value represent in hypothesis testing?\n",
        "\n",
        "P-value in Hypothesis Testing:\n",
        "\n",
        "- The P-value is the probability of obtaining test results at least as extreme as the observed results, assuming the null hypothesis is true.\n",
        "- It quantifies the evidence against the null hypothesis.\n",
        "- A smaller P-value indicates stronger evidence to reject the null hypothesis.\n",
        "- If the P-value is less than or equal to the chosen significance level (α), we reject the null hypothesis.\n",
        "- If the P-value is greater than α, we fail to reject the null hypothesis.\n",
        "- The P-value helps determine the statistical significance of the observed effect."
      ],
      "metadata": {
        "id": "2Pd5IR826wTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "voM1bRVE69Lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_yiI6DjP69FT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.  How do you interpret the P-value in hypothesis testing?\n",
        "\n",
        "Interpreting the P-value in Hypothesis Testing:\n",
        "\n",
        "- If the P-value ≤ significance level (α):\n",
        "    - Reject the null hypothesis (H0).\n",
        "    - There is sufficient evidence to support the alternative hypothesis (H1).\n",
        "    - The observed result is statistically significant.\n",
        "\n",
        "- If the P-value > significance level (α):\n",
        "    - Fail to reject the null hypothesis.\n",
        "    - There is insufficient evidence to support the alternative hypothesis.\n",
        "    - The observed result is not statistically significant.\n",
        "\n",
        "- A small P-value indicates strong evidence against H0.\n",
        "- A large P-value suggests that the data is consistent with H0."
      ],
      "metadata": {
        "id": "RQ1fjx1g685l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6UXrrSjX7NcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nBplmVq47NZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6.What are Type 1 and Type 2 errors in hypothesis testing?\n",
        "\n",
        "- Type 1 error = rejecting a true null hypothesis.\n",
        "- Type 2 error = failing to reject a false null hypothesis.\n",
        "\n",
        "- Type 1 Error (False Positive):\n",
        "  - Occurs when the null hypothesis (H0) is rejected even though it is true.\n",
        "  - The probability of making a Type 1 error is the significance level (α).\n",
        "  - Example: Concluding a new drug works when it actually does not.\n",
        "\n",
        "- Type 2 Error (False Negative):\n",
        "  - Occurs when the null hypothesis is not rejected even though the alternative hypothesis (H1) is true.\n",
        "  - The probability of making a Type 2 error is denoted by β.\n",
        "  - Example: Failing to detect that a new drug works when it actually does."
      ],
      "metadata": {
        "id": "zN3jxnGn7NWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GjDogkmf7izA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HZv6evMR7iw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Cw8c1nt7itc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. What is the difference between a one-tailed and a two-tailed test in hypothesis testing?\n",
        "\n",
        "- One-tailed: Directional hypothesis, more powerful if direction is correct.\n",
        "- Two-tailed: Non-directional hypothesis, more conservative.\n",
        "\n",
        "- One-tailed Test:\n",
        "  - Tests for an effect in only one direction (either greater than or less than).\n",
        "  - The entire significance level (α) is placed in one tail of the distribution.\n",
        "  - Used when the research hypothesis predicts the direction of the effect.\n",
        "  - Example: Testing if a new drug is **better** than the current drug.\n",
        "\n",
        "- Two-tailed Test:\n",
        "  - Tests for an effect in both directions (either greater than or less than).\n",
        "  - The significance level (α) is split equally between the two tails.\n",
        "  - Used when the research hypothesis does not predict the direction.\n",
        "  - Example: Testing if a new drug has **any different effect** (better or worse) than the current drug."
      ],
      "metadata": {
        "id": "2D8EzEKN7iqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Es7yTRk7wUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zji6lF077wR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. What is the Z-test, and when is it used in hypothesis testing?\n",
        "\n",
        "- A Z-test is a statistical test used to determine if there is a significant difference between sample and population means or between two sample means when the population variance is known.\n",
        "- It assumes that the sample size is large (typically n > 30), or the population is normally distributed.\n",
        "- The test statistic follows a standard normal distribution (Z-distribution).\n",
        "- Common uses:\n",
        "  - Testing the mean of a single sample against a known population mean.\n",
        "  - Comparing means of two samples when population variances are known.\n",
        "- Formula for the Z-test statistic for a single sample mean:\n",
        "  Z = (sample_mean - population_mean) / (population_std_dev / sqrt(sample_size))\n",
        "\n",
        "When to use:\n",
        "- When population variance is known.\n",
        "- Large sample sizes or normal population distribution.\n",
        "- Useful for testing hypotheses about means."
      ],
      "metadata": {
        "id": "lJdXvzHY7wPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mew_YH5Q79rM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HT3qW6aD79pN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. How do you calculate the Z-score, and what does it represent in hypothesis testing?\n",
        "\n",
        "- The Z-score measures how many standard deviations a data point or sample mean is from the population mean.\n",
        "- Formula to calculate Z-score for a sample mean:\n",
        "\n",
        "  Z = (X̄ - μ) / (σ / √n)\n",
        "\n",
        "  Where:\n",
        "    X̄ = sample mean\n",
        "    μ = population mean\n",
        "    σ = population standard deviation\n",
        "    n = sample size\n",
        "\n",
        "- Interpretation:\n",
        "  - A large absolute Z-score (positive or negative) indicates the sample mean is far from the population mean.\n",
        "  - In hypothesis testing, the Z-score helps determine how likely the observed sample mean is under the null hypothesis.\n",
        "  - The Z-score is compared to critical values from the standard normal distribution to decide whether to reject the null hypothesis."
      ],
      "metadata": {
        "id": "sC61d7SF79m3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_v_oDP808Ufd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X_ypS-uH8Udv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "18rFhzNM8Ub0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. What is the relationship between Z-test and T-test in hypothesis testing?\n",
        "\n",
        "- Use Z-test when population variance is known and sample size is large.\n",
        "- Use T-test when population variance is unknown or sample size is small.\n",
        "\n",
        "- Both tests are used to determine if there is a significant difference between means.\n",
        "- The key difference lies in knowledge about population variance and sample size:\n",
        "\n",
        "1. Z-test:\n",
        "   - Used when the population variance (or standard deviation) is known.\n",
        "   - Suitable for large sample sizes (usually n > 30).\n",
        "   - Uses the standard normal distribution (Z-distribution).\n",
        "\n",
        "2. T-test:\n",
        "   - Used when the population variance is unknown.\n",
        "   - Suitable for small sample sizes (usually n ≤ 30).\n",
        "   - Uses the Student’s t-distribution, which accounts for extra uncertainty from estimating the population variance.\n",
        "\n",
        "- As sample size increases, the t-distribution approaches the normal distribution, so T-test results become similar to Z-test results."
      ],
      "metadata": {
        "id": "-6Y157Cm8UZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hy8l9qwE8ndQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O9VE6HIi8nbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. What is a confidence interval, and how is it used to interpret statistical results?\n",
        "\n",
        "- A confidence interval is a range of values, derived from sample data, that is likely to contain the true population parameter (e.g., mean) with a specified level of confidence.\n",
        "- It is usually expressed with a confidence level, such as 95% or 99%, indicating the probability that the interval contains the true parameter.\n",
        "- Formula for a confidence interval for a population mean (when population standard deviation is known):\n",
        "\n",
        "  CI = sample_mean ± Z*(σ / √n)\n",
        "\n",
        "  Where:\n",
        "    - Z* is the critical value from the standard normal distribution corresponding to the confidence level\n",
        "    - σ is the population standard deviation\n",
        "    - n is the sample size\n",
        "\n",
        "- Interpretation:\n",
        "  - If we say a 95% confidence interval for a mean is (50, 60), it means we are 95% confident that the true population mean lies between 50 and 60.\n",
        "  - Confidence intervals provide more information than hypothesis tests because they estimate the range of plausible values for the parameter.\n",
        "- Use:\n",
        "  - To estimate population parameters with an indication of uncertainty.\n",
        "  - To assess the precision of sample estimates."
      ],
      "metadata": {
        "id": "OLJoF3kb8nY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iMPNlt5_80Rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qQf9J_Yg80Pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. What is the margin of error, and how does it affect the confidence interval?\n",
        "\n",
        "- The margin of error (MOE) is the maximum expected difference between the sample estimate and the true population parameter.\n",
        "- It quantifies the amount of uncertainty or potential error in the estimate.\n",
        "- Formula for margin of error when estimating a population mean (with known population standard deviation):\n",
        "\n",
        "  MOE = Z* × (σ / √n)\n",
        "\n",
        "  Where:\n",
        "    - Z* is the critical value corresponding to the desired confidence level (e.g., 1.96 for 95%)\n",
        "    - σ is the population standard deviation\n",
        "    - n is the sample size\n",
        "\n",
        "- How MOE affects Confidence Interval (CI):\n",
        "  - The confidence interval is constructed as:\n",
        "\n",
        "    CI = sample_mean ± MOE\n",
        "\n",
        "  - A larger margin of error results in a wider confidence interval, indicating less precision.\n",
        "  - A smaller margin of error results in a narrower confidence interval, indicating more precise estimates.\n",
        "\n",
        "- Factors affecting MOE:\n",
        "  - Increasing sample size decreases MOE, leading to more precise estimates.\n",
        "  - Higher confidence levels increase MOE, resulting in wider intervals."
      ],
      "metadata": {
        "id": "fEePMOPD81VK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VRcHUR4h9CYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TQURuiZd9COO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 13. How is Bayes' Theorem used in statistics, and what is its significance?\n",
        "\n",
        "- Bayes' Theorem is a mathematical formula used to update the probability of a hypothesis based on new evidence or data.\n",
        "- It expresses how to revise prior beliefs (prior probability) into updated beliefs (posterior probability) after observing new data.\n",
        "- The formula is:\n",
        "\n",
        "  P(A|B) = [P(B|A) × P(A)] / P(B)\n",
        "\n",
        "  Where:\n",
        "    - P(A|B) is the posterior probability: probability of event A given event B occurred.\n",
        "    - P(B|A) is the likelihood: probability of event B given event A.\n",
        "    - P(A) is the prior probability of event A.\n",
        "    - P(B) is the total probability of event B.\n",
        "\n",
        "- Significance:\n",
        "  - Allows incorporation of new information to improve decision-making.\n",
        "  - Widely used in statistics, machine learning, medical diagnosis, and many real-world applications.\n",
        "  - Helps in updating probabilities dynamically as more data becomes available."
      ],
      "metadata": {
        "id": "qfOOywjC9CHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TXpqLINa9PQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G8Hno-zl9PIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 14. What is the Chi-square distribution, and when is it used?\n",
        "\n",
        "- The Chi-square (χ²) distribution is a continuous probability distribution that arises in statistics mainly when dealing with variance estimates of a normally distributed population.\n",
        "- It is the distribution of a sum of the squares of independent standard normal random variables.\n",
        "- The shape of the Chi-square distribution depends on the degrees of freedom (df).\n",
        "\n",
        "Common uses of Chi-square distribution:\n",
        "- Chi-square test for independence: To test if two categorical variables are independent.\n",
        "- Chi-square goodness-of-fit test: To see how well observed data fits an expected distribution.\n",
        "- Test for population variance: To test hypotheses about the variance of a normally distributed population.\n",
        "\n",
        "Characteristics:\n",
        "- Only takes positive values (≥ 0).\n",
        "- Skewed to the right, but becomes more symmetric as degrees of freedom increase."
      ],
      "metadata": {
        "id": "_MG7oZLK9O96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "khvHYyBm9a0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lueZvAYF9ayO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 15. What is the Chi-square goodness of fit test, and how is it applied?\n",
        "\n",
        "- The Chi-square goodness of fit test is used to determine whether an observed frequency distribution matches an expected distribution.\n",
        "- It tests if the observed categorical data fits a specific theoretical distribution.\n",
        "- The test compares observed counts with expected counts under the null hypothesis.\n",
        "\n",
        "Steps to apply the test:\n",
        "1. Define the null hypothesis (H0): The observed data follows the expected distribution.\n",
        "2. Calculate the expected frequencies based on the theoretical distribution.\n",
        "3. Compute the test statistic:\n",
        "\n",
        "   χ² = Σ [(Observed - Expected)² / Expected]\n",
        "\n",
        "4. Determine the degrees of freedom: df = (number of categories - 1)\n",
        "5. Compare the test statistic to the critical value from the Chi-square distribution or use the p-value.\n",
        "6. Make a decision:\n",
        "   - If χ² > critical value or p-value < significance level, reject H0.\n",
        "   - Otherwise, fail to reject H0.\n",
        "\n",
        "Application examples:\n",
        "- Testing if a dice is fair by comparing observed roll frequencies to expected equal probabilities.\n",
        "- Checking if genetic traits follow expected Mendelian ratios."
      ],
      "metadata": {
        "id": "Agr9FQDx9cKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FD0GVdAX9sqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 16.  What is an ANOVA test, and what are its assumptions?\n",
        "\n",
        "- ANOVA is a statistical method used to compare the means of three or more groups to see if at least one group mean is significantly different from the others.\n",
        "- It analyzes the variance within groups and between groups to determine if the observed differences are statistically significant.\n",
        "- Commonly used when comparing more than two groups to avoid multiple t-tests and reduce Type 1 error.\n",
        "\n",
        "Assumptions of ANOVA:\n",
        "1. Independence: Observations are independent of each other.\n",
        "2. Normality: The data in each group should be approximately normally distributed.\n",
        "3. Homogeneity of variances (Homoscedasticity): The variances across groups are equal.\n",
        "4. The dependent variable is measured at the interval or ratio level."
      ],
      "metadata": {
        "id": "JoYgK24q9soG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JkxDNGZP95Jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QE0zSvls95HT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 17. What are the different types of ANOVA tests?\n",
        "\n",
        "1. One-Way ANOVA:\n",
        "   - Compares the means of three or more independent groups based on one factor.\n",
        "   - Example: Testing if different diets affect weight loss.\n",
        "\n",
        "2. Two-Way ANOVA:\n",
        "   - Examines the effect of two independent factors on a dependent variable.\n",
        "   - Can also test for interaction effects between factors.\n",
        "   - Example: Studying how diet type and exercise routine together affect weight loss.\n",
        "\n",
        "3. Repeated Measures ANOVA:\n",
        "   - Used when the same subjects are measured multiple times under different conditions.\n",
        "   - Accounts for the correlation between repeated measures.\n",
        "   - Example: Measuring blood pressure of patients before, during, and after treatment.\n",
        "\n",
        "4. MANOVA (Multivariate ANOVA):\n",
        "   - Extends ANOVA when there are two or more dependent variables.\n",
        "   - Tests differences in multiple dependent variables simultaneously.\n",
        "   - Example: Testing effects of a drug on both blood pressure and cholesterol levels."
      ],
      "metadata": {
        "id": "1TuVFmR395E5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1G3rDf7S-E_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RkjQ9qPj-FYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 18. What is the F-test, and how does it relate to hypothesis testing?\n",
        "\n",
        "- The F-test is used to compare two variances to determine if they come from populations with equal variances.\n",
        "- It is the basis for tests like ANOVA, which compares the variance between group means to the variance within groups.\n",
        "- The test statistic follows an F-distribution, which depends on two sets of degrees of freedom (numerator and denominator).\n",
        "\n",
        "How it works:\n",
        "- Calculate the ratio of two variances (variance between groups / variance within groups).\n",
        "- If the ratio is significantly greater than 1, it suggests that group means are different.\n",
        "\n",
        "Use cases:\n",
        "- Testing equality of variances (e.g., Levene’s test).\n",
        "- Testing differences among multiple group means (ANOVA).\n",
        "- Model comparison in regression analysis.\n",
        "\n",
        "Relation to hypothesis testing:\n",
        "- Null hypothesis (H0): Variances (or group means) are equal.\n",
        "- Alternative hypothesis (H1): At least one variance (or mean) is different.\n",
        "- Based on the F-statistic and critical value or p-value, decide to reject or fail to reject H0."
      ],
      "metadata": {
        "id": "d5LDJpVe-E9W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}